{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision is a python library that complements pytorch/torch with functionality related to \n",
    "# computer vision (to images) in torchvision.datasets we can find toy datasets containing images\n",
    "from torchvision.datasets import FashionMNIST\n",
    "# in torchvision.transforms we find transforms: these take in an image and does something to it\n",
    "# there are transforms that rotate images, transforms that crop images etc.\n",
    "# these are useful as a way to increase the size of our dataset: it is usually good for the model to see as much data as possible\n",
    "# we will make use of ToTensor(), which converts PIL (Python Image Library) images to a format that pytorch understands (a tensor)\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training dataset of FashionMNIST\n",
    "# this dataset contains 60000 images, and for each one of them, the index of a class\n",
    "# (you can find the order of the classes in the presentation / notebook)\n",
    "# notice we pass transform = ToTensor()\n",
    "mnist_train_dataset = FashionMNIST(root = \"/data\", train = True, transform = ToTensor(), download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "          0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "          0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "          0.0157, 0.0000, 0.0000, 0.0118],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "          0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0471, 0.0392, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "          0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "          0.3020, 0.5098, 0.2824, 0.0588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "          0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "          0.5529, 0.3451, 0.6745, 0.2588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "          0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "          0.4824, 0.7686, 0.8980, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "          0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "          0.8745, 0.9608, 0.6784, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "          0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "          0.8627, 0.9529, 0.7922, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "          0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "          0.8863, 0.7725, 0.8196, 0.2039],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "          0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "          0.9608, 0.4667, 0.6549, 0.2196],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "          0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "          0.8510, 0.8196, 0.3608, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "          0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "          0.8549, 1.0000, 0.3020, 0.0000],\n",
       "         [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "          0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "          0.8784, 0.9569, 0.6235, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "          0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "          0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "          0.9137, 0.9333, 0.8431, 0.0000],\n",
       "         [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "          0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "          0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "          0.8627, 0.9098, 0.9647, 0.0000],\n",
       "         [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "          0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "          0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "          0.8706, 0.8941, 0.8824, 0.0000],\n",
       "         [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "          0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "          0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "          0.8745, 0.8784, 0.8980, 0.1137],\n",
       "         [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "          0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "          0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "          0.8627, 0.8667, 0.9020, 0.2627],\n",
       "         [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "          0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "          0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "          0.7098, 0.8039, 0.8078, 0.4510],\n",
       "         [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "          0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "          0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "          0.6549, 0.6941, 0.8235, 0.3608],\n",
       "         [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "          0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "          0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "          0.7529, 0.8471, 0.6667, 0.0000],\n",
       "         [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "          0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "          0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "          0.3882, 0.2275, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "          0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each example contains 2 things: an image (analogous to the population in the first part, aka the input)\n",
    "# and a class (analogous to the profit in the first part, aka the output)\n",
    "mnist_train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAg2klEQVR4nO3de2zV9f3H8ddpoYdC28NK6U3KVRAjFzeEWlF+KhXoEiNCJl7+gM1LZMUMmdOwqOhcUseSzbgxTLYFZiLeEoFolAWLlDkuDoQgmSOAKGBpucyeU3qn/f7+IHZWrp+P5/Tdlucj+Sb0nO+L78cv3/blt+f03VAQBIEAAOhkSdYLAABcniggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmOhlvYBva2trU2VlpdLT0xUKhayXAwBwFASBamtrlZ+fr6Sk89/ndLkCqqysVEFBgfUyAADf0eHDhzVo0KDzPt/lvgWXnp5uvQQAQBxc7Ot5wgpo2bJlGjp0qPr06aPCwkJ99NFHl5Tj224A0DNc7Ot5Qgro9ddf16JFi7RkyRJ9/PHHGj9+vKZPn65jx44l4nAAgO4oSIBJkyYFpaWl7R+3trYG+fn5QVlZ2UWz0Wg0kMTGxsbG1s23aDR6wa/3cb8Dam5u1o4dO1RcXNz+WFJSkoqLi7Vly5az9m9qalIsFuuwAQB6vrgX0IkTJ9Ta2qqcnJwOj+fk5Kiqquqs/cvKyhSJRNo33gEHAJcH83fBLV68WNFotH07fPiw9ZIAAJ0g7j8HlJWVpeTkZFVXV3d4vLq6Wrm5uWftHw6HFQ6H470MAEAXF/c7oJSUFE2YMEHl5eXtj7W1tam8vFxFRUXxPhwAoJtKyCSERYsWae7cubruuus0adIkvfDCC6qrq9OPf/zjRBwOANANJaSA5syZo+PHj+vpp59WVVWVrr32Wq1bt+6sNyYAAC5foSAIAutFfFMsFlMkErFeBgDgO4pGo8rIyDjv8+bvggMAXJ4oIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACAiV7WCwC6klAo5JwJgiABKzlbenq6c+bGG2/0OtZ7773nlXPlc76Tk5OdM6dPn3bOdHU+585Xoq5x7oAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYYBgp8A1JSe7/T9ba2uqcufLKK50zDzzwgHOmoaHBOSNJdXV1zpnGxkbnzEcffeSc6czBoj4DP32uIZ/jdOZ5cB0AGwSB2traLrofd0AAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMMIwU+AbXoYuS3zDSW2+91TlTXFzsnDly5IhzRpLC4bBzpm/fvs6Z2267zTnzl7/8xTlTXV3tnJHODNV05XM9+EhLS/PKXcqQ0G+rr6/3OtbFcAcEADBBAQEATMS9gJ555hmFQqEO2+jRo+N9GABAN5eQ14CuueYavf/++/87SC9eagIAdJSQZujVq5dyc3MT8VcDAHqIhLwGtG/fPuXn52v48OG67777dOjQofPu29TUpFgs1mEDAPR8cS+gwsJCrVy5UuvWrdPy5ct18OBB3XTTTaqtrT3n/mVlZYpEIu1bQUFBvJcEAOiC4l5AJSUl+tGPfqRx48Zp+vTpevfdd1VTU6M33njjnPsvXrxY0Wi0fTt8+HC8lwQA6IIS/u6A/v37a9SoUdq/f/85nw+Hw14/9AYA6N4S/nNAp06d0oEDB5SXl5foQwEAupG4F9Bjjz2miooKff7559q8ebPuvPNOJScn65577on3oQAA3VjcvwV35MgR3XPPPTp58qQGDhyoG2+8UVu3btXAgQPjfSgAQDcW9wJ67bXX4v1XAp2mubm5U44zceJE58zQoUOdMz7DVSUpKcn9myN///vfnTPf//73nTNLly51zmzfvt05I0mffPKJc+bTTz91zkyaNMk543MNSdLmzZudM1u2bHHaPwiCS/qRGmbBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMJHwX0gHWAiFQl65IAicM7fddptz5rrrrnPOnO/X2l9Iv379nDOSNGrUqE7J/Otf/3LOnO+XW15IWlqac0aSioqKnDOzZs1yzrS0tDhnfM6dJD3wwAPOmaamJqf9T58+rX/84x8X3Y87IACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACAiVDgM/43gWKxmCKRiPUykCC+U6o7i8+nw9atW50zQ4cOdc748D3fp0+fds40Nzd7HctVY2Ojc6atrc3rWB9//LFzxmdat8/5njFjhnNGkoYPH+6cueKKK7yOFY1GlZGRcd7nuQMCAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgopf1AnB56WKzb+Piq6++cs7k5eU5ZxoaGpwz4XDYOSNJvXq5f2lIS0tzzvgMFk1NTXXO+A4jvemmm5wzN9xwg3MmKcn9XiA7O9s5I0nr1q3zyiUCd0AAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMMIwU+I769u3rnPEZPumTqa+vd85IUjQadc6cPHnSOTN06FDnjM9A21Ao5JyR/M65z/XQ2trqnPEdsFpQUOCVSwTugAAAJiggAIAJ5wLatGmTbr/9duXn5ysUCmnNmjUdng+CQE8//bTy8vKUmpqq4uJi7du3L17rBQD0EM4FVFdXp/Hjx2vZsmXnfH7p0qV68cUX9dJLL2nbtm3q16+fpk+f7vWLpwAAPZfzmxBKSkpUUlJyzueCINALL7ygJ598UnfccYck6eWXX1ZOTo7WrFmju++++7utFgDQY8T1NaCDBw+qqqpKxcXF7Y9FIhEVFhZqy5Yt58w0NTUpFot12AAAPV9cC6iqqkqSlJOT0+HxnJyc9ue+raysTJFIpH3rSm8RBAAkjvm74BYvXqxoNNq+HT582HpJAIBOENcCys3NlSRVV1d3eLy6urr9uW8Lh8PKyMjosAEAer64FtCwYcOUm5ur8vLy9sdisZi2bdumoqKieB4KANDNOb8L7tSpU9q/f3/7xwcPHtSuXbuUmZmpwYMHa+HChfr1r3+tkSNHatiwYXrqqaeUn5+vmTNnxnPdAIBuzrmAtm/frltuuaX940WLFkmS5s6dq5UrV+rxxx9XXV2dHnroIdXU1OjGG2/UunXr1KdPn/itGgDQ7YUCn8l+CRSLxRSJRKyXgQTxGQrpMxDSZ7ijJKWlpTlndu7c6ZzxOQ8NDQ3OmXA47JyRpMrKSufMt1/7vRQ33HCDc8Zn6KnPgFBJSklJcc7U1tY6Z3y+5vm+YcvnGr///vud9m9tbdXOnTsVjUYv+Lq++bvgAACXJwoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACedfxwB8Fz7D15OTk50zvtOw58yZ45w532/7vZDjx487Z1JTU50zbW1tzhlJ6tevn3OmoKDAOdPc3Oyc8Znw3dLS4pyRpF693L9E+vw7DRgwwDmzbNky54wkXXvttc4Zn/NwKbgDAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIJhpOhUPkMNfQZW+tqzZ49zpqmpyTnTu3dv50xnDmXNzs52zjQ2NjpnTp486ZzxOXd9+vRxzkh+Q1m/+uor58yRI0ecM/fee69zRpJ++9vfOme2bt3qdayL4Q4IAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACAict6GGkoFPLK+QyFTEpy73qf9bW0tDhn2tranDO+Tp8+3WnH8vHuu+86Z+rq6pwzDQ0NzpmUlBTnTBAEzhlJOn78uHPG5/PCZ0iozzXuq7M+n3zO3bhx45wzkhSNRr1yicAdEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABM9ZhipzzC/1tZWr2N19YGaXdmUKVOcM7Nnz3bOTJ482TkjSfX19c6ZkydPOmd8Bov26uX+6ep7jfucB5/PwXA47JzxGWDqO5TV5zz48LkeTp065XWsWbNmOWfefvttr2NdDHdAAAATFBAAwIRzAW3atEm333678vPzFQqFtGbNmg7Pz5s3T6FQqMM2Y8aMeK0XANBDOBdQXV2dxo8fr2XLlp13nxkzZujo0aPt26uvvvqdFgkA6HmcX9UsKSlRSUnJBfcJh8PKzc31XhQAoOdLyGtAGzduVHZ2tq666irNnz//gu8SampqUiwW67ABAHq+uBfQjBkz9PLLL6u8vFy/+c1vVFFRoZKSkvO+HbSsrEyRSKR9KygoiPeSAABdUNx/Dujuu+9u//PYsWM1btw4jRgxQhs3btTUqVPP2n/x4sVatGhR+8exWIwSAoDLQMLfhj18+HBlZWVp//7953w+HA4rIyOjwwYA6PkSXkBHjhzRyZMnlZeXl+hDAQC6EedvwZ06darD3czBgwe1a9cuZWZmKjMzU88++6xmz56t3NxcHThwQI8//riuvPJKTZ8+Pa4LBwB0b84FtH37dt1yyy3tH3/9+s3cuXO1fPly7d69W3/7299UU1Oj/Px8TZs2Tc8995zXzCcAQM8VCnyn9CVILBZTJBKxXkbcZWZmOmfy8/OdMyNHjuyU40h+Qw1HjRrlnGlqanLOJCX5fXe5paXFOZOamuqcqaysdM707t3bOeMz5FKSBgwY4Jxpbm52zvTt29c5s3nzZudMWlqac0byG57b1tbmnIlGo84Zn+tBkqqrq50zV199tdexotHoBV/XZxYcAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBE3H8lt5Xrr7/eOfPcc895HWvgwIHOmf79+ztnWltbnTPJycnOmZqaGueMJJ0+fdo5U1tb65zxmbIcCoWcM5LU0NDgnPGZznzXXXc5Z7Zv3+6cSU9Pd85IfhPIhw4d6nUsV2PHjnXO+J6Hw4cPO2fq6+udMz4T1X0nfA8ZMsQrlwjcAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDRZYeRJiUlOQ2UfPHFF52PkZeX55yR/IaE+mR8hhr6SElJ8cr5/Df5DPv0EYlEvHI+gxqff/5554zPeZg/f75zprKy0jkjSY2Njc6Z8vJy58xnn33mnBk5cqRzZsCAAc4ZyW8Qbu/evZ0zSUnu9wItLS3OGUk6fvy4Vy4RuAMCAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgIhQEQWC9iG+KxWKKRCK67777nIZk+gyEPHDggHNGktLS0jolEw6HnTM+fIYnSn4DPw8fPuyc8RmoOXDgQOeM5DcUMjc31zkzc+ZM50yfPn2cM0OHDnXOSH7X64QJEzol4/Nv5DNU1PdYvsN9XbkMa/4mn8/366+/3mn/trY2ffnll4pGo8rIyDjvftwBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMNHLegHnc/z4caeheT5DLtPT050zktTU1OSc8Vmfz0BIn0GIFxoWeCH//e9/nTNffPGFc8bnPDQ0NDhnJKmxsdE5c/r0aefM6tWrnTOffPKJc8Z3GGlmZqZzxmfgZ01NjXOmpaXFOePzbySdGarpymfYp89xfIeR+nyNGDVqlNP+p0+f1pdffnnR/bgDAgCYoIAAACacCqisrEwTJ05Uenq6srOzNXPmTO3du7fDPo2NjSotLdWAAQOUlpam2bNnq7q6Oq6LBgB0f04FVFFRodLSUm3dulXr169XS0uLpk2bprq6uvZ9Hn30Ub399tt68803VVFRocrKSs2aNSvuCwcAdG9Ob0JYt25dh49Xrlyp7Oxs7dixQ1OmTFE0GtVf//pXrVq1SrfeeqskacWKFbr66qu1detW59+qBwDoub7Ta0DRaFTS/94xs2PHDrW0tKi4uLh9n9GjR2vw4MHasmXLOf+OpqYmxWKxDhsAoOfzLqC2tjYtXLhQkydP1pgxYyRJVVVVSklJUf/+/Tvsm5OTo6qqqnP+PWVlZYpEIu1bQUGB75IAAN2IdwGVlpZqz549eu21177TAhYvXqxoNNq++fy8DACg+/H6QdQFCxbonXfe0aZNmzRo0KD2x3Nzc9Xc3KyampoOd0HV1dXKzc09598VDocVDod9lgEA6Mac7oCCINCCBQu0evVqbdiwQcOGDevw/IQJE9S7d2+Vl5e3P7Z3714dOnRIRUVF8VkxAKBHcLoDKi0t1apVq7R27Vqlp6e3v64TiUSUmpqqSCSi+++/X4sWLVJmZqYyMjL0yCOPqKioiHfAAQA6cCqg5cuXS5JuvvnmDo+vWLFC8+bNkyT9/ve/V1JSkmbPnq2mpiZNnz5df/rTn+KyWABAzxEKgiCwXsQ3xWIxRSIRjR07VsnJyZec+/Of/+x8rBMnTjhnJKlfv37OmQEDBjhnfAY1njp1yjnjMzxRknr1cn8J0WfoYt++fZ0zPgNMJb9zkZTk/l4en0+7b7+79FJ884fEXfgMc/3qq6+cMz6v//p83voMMJX8hpj6HCs1NdU5c77X1S/GZ4jpK6+84rR/U1OT/vjHPyoajV5w2DGz4AAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJrx+I2pn+OSTT5z2f+utt5yP8ZOf/MQ5I0mVlZXOmc8++8w509jY6JzxmQLtOw3bZ4JvSkqKc8ZlKvrXmpqanDOS1Nra6pzxmWxdX1/vnDl69KhzxnfYvc958JmO3lnXeHNzs3NG8ptI75PxmaDtM6lb0lm/SPRSVFdXO+1/qeebOyAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmQoHvtMIEicViikQinXKskpISr9xjjz3mnMnOznbOnDhxwjnjMwjRZ/Ck5Dck1GcYqc+QS5+1SVIoFHLO+HwK+QyA9cn4nG/fY/mcOx8+x3Edpvld+JzztrY250xubq5zRpJ2797tnLnrrru8jhWNRpWRkXHe57kDAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYKLLDiMNhUJOQwd9hvl1pltuucU5U1ZW5pzxGXrqO/w1Kcn9/198hoT6DCP1HbDq49ixY84Zn0+7L7/80jnj+3lx6tQp54zvAFhXPueupaXF61j19fXOGZ/Pi/Xr1ztnPv30U+eMJG3evNkr54NhpACALokCAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAICJLjuMFJ1n9OjRXrmsrCznTE1NjXNm0KBBzpnPP//cOSP5Da08cOCA17GAno5hpACALokCAgCYcCqgsrIyTZw4Uenp6crOztbMmTO1d+/eDvvcfPPN7b/L5+vt4YcfjuuiAQDdn1MBVVRUqLS0VFu3btX69evV0tKiadOmqa6ursN+Dz74oI4ePdq+LV26NK6LBgB0f06/anLdunUdPl65cqWys7O1Y8cOTZkypf3xvn37Kjc3Nz4rBAD0SN/pNaBoNCpJyszM7PD4K6+8oqysLI0ZM0aLFy++4K+1bWpqUiwW67ABAHo+pzugb2pra9PChQs1efJkjRkzpv3xe++9V0OGDFF+fr52796tJ554Qnv37tVbb711zr+nrKxMzz77rO8yAADdlPfPAc2fP1/vvfeePvzwwwv+nMaGDRs0depU7d+/XyNGjDjr+aamJjU1NbV/HIvFVFBQ4LMkeOLngP6HnwMC4udiPwfkdQe0YMECvfPOO9q0adNFvzgUFhZK0nkLKBwOKxwO+ywDANCNORVQEAR65JFHtHr1am3cuFHDhg27aGbXrl2SpLy8PK8FAgB6JqcCKi0t1apVq7R27Vqlp6erqqpKkhSJRJSamqoDBw5o1apV+uEPf6gBAwZo9+7devTRRzVlyhSNGzcuIf8BAIDuyamAli9fLunMD5t+04oVKzRv3jylpKTo/fff1wsvvKC6ujoVFBRo9uzZevLJJ+O2YABAz+D8LbgLKSgoUEVFxXdaEADg8sA0bABAQjANGwDQJVFAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDR5QooCALrJQAA4uBiX8+7XAHV1tZaLwEAEAcX+3oeCrrYLUdbW5sqKyuVnp6uUCjU4blYLKaCggIdPnxYGRkZRiu0x3k4g/NwBufhDM7DGV3hPARBoNraWuXn5ysp6fz3Ob06cU2XJCkpSYMGDbrgPhkZGZf1BfY1zsMZnIczOA9ncB7OsD4PkUjkovt0uW/BAQAuDxQQAMBEtyqgcDisJUuWKBwOWy/FFOfhDM7DGZyHMzgPZ3Sn89Dl3oQAALg8dKs7IABAz0EBAQBMUEAAABMUEADARLcpoGXLlmno0KHq06ePCgsL9dFHH1kvqdM988wzCoVCHbbRo0dbLyvhNm3apNtvv135+fkKhUJas2ZNh+eDINDTTz+tvLw8paamqri4WPv27bNZbAJd7DzMmzfvrOtjxowZNotNkLKyMk2cOFHp6enKzs7WzJkztXfv3g77NDY2qrS0VAMGDFBaWppmz56t6upqoxUnxqWch5tvvvms6+Hhhx82WvG5dYsCev3117Vo0SItWbJEH3/8scaPH6/p06fr2LFj1kvrdNdcc42OHj3avn344YfWS0q4uro6jR8/XsuWLTvn80uXLtWLL76ol156Sdu2bVO/fv00ffp0NTY2dvJKE+ti50GSZsyY0eH6ePXVVztxhYlXUVGh0tJSbd26VevXr1dLS4umTZumurq69n0effRRvf3223rzzTdVUVGhyspKzZo1y3DV8Xcp50GSHnzwwQ7Xw9KlS41WfB5BNzBp0qSgtLS0/ePW1tYgPz8/KCsrM1xV51uyZEkwfvx462WYkhSsXr26/eO2trYgNzc3+O1vf9v+WE1NTRAOh4NXX33VYIWd49vnIQiCYO7cucEdd9xhsh4rx44dCyQFFRUVQRCc+bfv3bt38Oabb7bv8+mnnwaSgi1btlgtM+G+fR6CIAj+7//+L/jZz35mt6hL0OXvgJqbm7Vjxw4VFxe3P5aUlKTi4mJt2bLFcGU29u3bp/z8fA0fPlz33XefDh06ZL0kUwcPHlRVVVWH6yMSiaiwsPCyvD42btyo7OxsXXXVVZo/f75OnjxpvaSEikajkqTMzExJ0o4dO9TS0tLhehg9erQGDx7co6+Hb5+Hr73yyivKysrSmDFjtHjxYtXX11ss77y63DDSbztx4oRaW1uVk5PT4fGcnBz95z//MVqVjcLCQq1cuVJXXXWVjh49qmeffVY33XST9uzZo/T0dOvlmaiqqpKkc14fXz93uZgxY4ZmzZqlYcOG6cCBA/rlL3+pkpISbdmyRcnJydbLi7u2tjYtXLhQkydP1pgxYySduR5SUlLUv3//Dvv25OvhXOdBku69914NGTJE+fn52r17t5544gnt3btXb731luFqO+ryBYT/KSkpaf/zuHHjVFhYqCFDhuiNN97Q/fffb7gydAV33313+5/Hjh2rcePGacSIEdq4caOmTp1quLLEKC0t1Z49ey6L10Ev5Hzn4aGHHmr/89ixY5WXl6epU6fqwIEDGjFiRGcv85y6/LfgsrKylJycfNa7WKqrq5Wbm2u0qq6hf//+GjVqlPbv32+9FDNfXwNcH2cbPny4srKyeuT1sWDBAr3zzjv64IMPOvz6ltzcXDU3N6umpqbD/j31ejjfeTiXwsJCSepS10OXL6CUlBRNmDBB5eXl7Y+1tbWpvLxcRUVFhiuzd+rUKR04cEB5eXnWSzEzbNgw5ebmdrg+YrGYtm3bdtlfH0eOHNHJkyd71PURBIEWLFig1atXa8OGDRo2bFiH5ydMmKDevXt3uB727t2rQ4cO9ajr4WLn4Vx27dolSV3rerB+F8SleO2114JwOBysXLky+Pe//x089NBDQf/+/YOqqirrpXWqn//858HGjRuDgwcPBv/85z+D4uLiICsrKzh27Jj10hKqtrY22LlzZ7Bz585AUvC73/0u2LlzZ/DFF18EQRAEzz//fNC/f/9g7dq1we7du4M77rgjGDZsWNDQ0GC88vi60Hmora0NHnvssWDLli3BwYMHg/fffz/4wQ9+EIwcOTJobGy0XnrczJ8/P4hEIsHGjRuDo0ePtm/19fXt+zz88MPB4MGDgw0bNgTbt28PioqKgqKiIsNVx9/FzsP+/fuDX/3qV8H27duDgwcPBmvXrg2GDx8eTJkyxXjlHXWLAgqCIPjDH/4QDB48OEhJSQkmTZoUbN261XpJnW7OnDlBXl5ekJKSElxxxRXBnDlzgv3791svK+E++OCDQNJZ29y5c4MgOPNW7KeeeirIyckJwuFwMHXq1GDv3r22i06AC52H+vr6YNq0acHAgQOD3r17B0OGDAkefPDBHvc/aef675cUrFixon2fhoaG4Kc//Wnwve99L+jbt29w5513BkePHrVbdAJc7DwcOnQomDJlSpCZmRmEw+HgyiuvDH7xi18E0WjUduHfwq9jAACY6PKvAQEAeiYKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAm/h+r5MpJjoz0fwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can matplotlib to display an image\n",
    "# mnist_train_dataset[0] contains the image and class, so we need mnist_train_dataset[0][0] to get the image\n",
    "# the image has shape 1 x 28 x 28: this represents a grayscale image in PyTorch (as in, not a color image)\n",
    "# if it were a color image, it would have had the shape 3 x 28 x 28, because we would have needed a red value, a green value and a blue value\n",
    "# since computers usually represent color as a mix of red, green and blue\n",
    "# matplotlib accepts tensors as input, but doesn't like the extra axis (dimension) of size 1\n",
    "# which is why we need to index one extra time into the array, leaving us with a 28 x 28 image\n",
    "# matplotlib requires cmap = \"gray\" to plot the image as a grayscale image\n",
    "# printing the class, we notice it has the value 9, which, by consulting the table from the presentation\n",
    "# we can see refers to an ankle boot, which the image seems to showcase\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mnist_train_dataset[0][0][0], cmap = \"gray\")\n",
    "mnist_train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the test dataset and has the same format as the train dataset\n",
    "# we use the test dataset only after we have trained the model\n",
    "# never ever ever train a model on the test dataset :)\n",
    "# the point of the test dataset is to distinguish between a model that has only managed to memorize the training dataset\n",
    "# (such a model can be found at the beginning of the presentation)\n",
    "# and a model that has managed to learn something from the dataset, and will be able to produce good outputs for inputs that\n",
    "# it hasn't already seen\n",
    "mnist_test_dataset = FashionMNIST(root = \"/data\", train = False, transform = ToTensor(), download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.FashionMNIST produces pytorch datasets (meaning instances of the torch.utils.data.Dataset class)\n",
    "# so we can pass them to a DataLoader\n",
    "mnist_train_loader = DataLoader(mnist_train_dataset, batch_size = 10)\n",
    "mnist_test_loader = DataLoader(mnist_test_dataset, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to use a model that looks like y = a1*x1+a2*x2+...an*xn+b on the image\n",
    "# just like we did for the population - profit dataset\n",
    "# this requires that we have a list of input features\n",
    "# but what we have at the moment is a matrix of input features\n",
    "# (since our image is represented as a matrix of pixels)\n",
    "# to deal with that, we take all the lines in the matrix of pixels\n",
    "# and place them next to each other, forming a long vector of pixels\n",
    "# nn.Flatten() implements this functionality\n",
    "flatten_layer = nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_images = flatten_layer(torch.rand((1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the flatten layer we got our hands on a vector of 784 elements\n",
    "# since our dataset has 10 classes, we need a model that outputs 10 values\n",
    "# which is why we pass 784 and 10 to nn.Linear\n",
    "# EXTRAish note: since we have 784 input features, and we are doing linear regression\n",
    "# we will end up with 784 parameters \n",
    "# however, we are not doing only one linear regression, we are doing 10 of them: one for each of the 10 outputs of the model\n",
    "# this new model has (ignoring the bias terms) 784 * 10 parameters\n",
    "# it sounds convenient to store these parameters in a matrix: the first line contains the 784 parameters for the first linear regression\n",
    "# and so on until the last line (row) which contains the 784 parameters for the 10th linear regression\n",
    "# we would end up with a 10 x 784 matrix (as we can see in the .weight attribute in the following cell)\n",
    "linear_regression_layer = nn.Linear(784, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 784])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# placing the parameters of the model in the shape of a matrix is not only convenient\n",
    "# you might remember that in matrix multiplication we take each row of the left matrix\n",
    "# and \"operate\" it with each columns of the right matrix\n",
    "# now if the first row is equal to a1, a2, ... a784 (our parameters)\n",
    "# and the first column is our flattened image vector p1, p2, ..., p784\n",
    "# that \"operate\" would lead us to a1*p1+a2*p2+...+a784*p784\n",
    "# by this logic we can see that (ignoring the bias term once again)\n",
    "# the output of nn.Linear(784, 10) will be equal to A*x.T\n",
    "# here, A is the matrix of parameters that we discusses above\n",
    "# and x.T is a matrix made out of a single column containing the model's inputs\n",
    "linear_regression_layer.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following 2 cells we are first using the nn.Linear(784, 10) layer, and then computing its output manually by essentially A @ x.T + bias.T. As a challenge you can try to figure out how everything works (Why do we need .float(), why do we need .reshape(-1, 1) etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  39.0755, -291.0217,  253.0401, -325.7418,  -80.6837,  289.0842,\n",
       "          141.4518, -162.6425,  254.1929,  -68.1710]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_layer(torch.arange(784).reshape(1, 784).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  39.0755],\n",
       "        [-291.0217],\n",
       "        [ 253.0401],\n",
       "        [-325.7418],\n",
       "        [ -80.6837],\n",
       "        [ 289.0842],\n",
       "        [ 141.4518],\n",
       "        [-162.6425],\n",
       "        [ 254.1929],\n",
       "        [ -68.1710]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_layer.weight.data @ (torch.arange(784).reshape(1, 784).float().T) + linear_regression_layer.bias.data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point we have done 2 things to the input image: flattened it, and passed it through a linear layer\n",
    "# we can express that in PyTorch using nn.Sequential: this layer will run its input through all of its components:\n",
    "# first through nn.Flatten(), and then through nn.Linear()\n",
    "model = nn.Sequential(nn.Flatten(), nn.Linear(28*28, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 784])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten()(torch.ones(10, 28, 28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8377, -0.1291,  0.4051, -0.5426, -0.1941,  0.1692,  0.0970,  0.5697,\n",
       "          0.0627,  0.5365]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at this input, we might wonder just what could it possibly means\n",
    "# for problems where we want to classify something as belonging to a class or another\n",
    "# (in our situation, images as containing a t-shirt, or a shirt, or trousers etc)\n",
    "# we will look at the output and figure out the position of the highest value\n",
    "# in our case, 0.5697 is the greatest value, and it is the 8th in the result\n",
    "# so our model has classified the image we gave it as having an ankle boot in it\n",
    "model(torch.ones((1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have a model, we will also need a loss function\n",
    "# for classification problems, the most used loss function is the cross entropy loss\n",
    "# the cross entropy loss first transforms the model's outputs to probabilities by using\n",
    "# the softmax function: this function takes in any numbers, and produces new numbers\n",
    "# that add up to 1, and that are positive (as a result of being positive and adding up to 1, they are also <= 1)\n",
    "# for numbers a, b, c the softmax function will output numbers e^a/(e^a+e^b+e^c), e^b/(e^a+e^b+e^c) and e^c/(e^a+e^b+e^c)\n",
    "# EXTRA: convince yourself those numbers are positive and add up to 1\n",
    "# In the previous cell, we took the largest value in the model's output and went with it\n",
    "# If we were to apply softmax, the largest value in the model's output would have still remained the largest value\n",
    "# However now we are also looking at the rest: we are doing a comparison between the largest value and the rest\n",
    "# To see that, notice that in the formula we are dividing (e^c) by (e^a+e^b+e^c), so we are comparing that value, e^c\n",
    "# to the rest of the values, e^a+e^b+e^c\n",
    "# CrossEntropyLoss than looks at what the correct value would have been, extracts the probability that correspond to it\n",
    "# and penalizes the model according to the formula -ln(p)\n",
    "# so if the model gave a probability of 1 for the correct class, than it would have received a penalty of -ln(1)=0, a.k.a no penalty\n",
    "# on the other hand, if the model gave a probability of 0 to the correct class, it would have been drastically penalized, by -ln(0),\n",
    "# which evaluates to infinity (as a limit, but as far as we're concerned the penalty would be extremely large)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0659)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to evaluate the cross entropy loss, we need to pass the model's outputs, and the correct class\n",
    "# for this example, PyTorch first applies Softmax, turning the value from 1, 2, 5 to\n",
    "# e^1/(e^1+e^2+e^5), e^2/(e^1+e^2+e^5), e^5/(e^1+e^2+e^5)\n",
    "# these end up equal to ~0.017, ~0.046 and ~0.93\n",
    "# we told the loss function that the correct class is class at index 1\n",
    "# so it applies a penalty of -ln(0.046)~3.07\n",
    "loss_function(torch.Tensor([[1., 2., 5.]]), torch.LongTensor([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below manually computes cross entropy loss for the same inputs as the nn.CrossEntropyLoss function received above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(158.5205)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denominator = torch.exp(torch.Tensor([1., 2., 5.])).sum()\n",
    "denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0466])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_for_class_1 = torch.exp(torch.Tensor([2])) / denominator\n",
    "probability_for_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0659])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty = -torch.log(probability_for_class_1)\n",
    "penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD optimizer, same as before\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    for pixels_batch, classes_batch in mnist_train_loader:\n",
    "        predicted_probabilities = model(pixels_batch)\n",
    "        loss = loss_function(predicted_probabilities, classes_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember we should test on the test dataset, and not the train dataset\n",
    "# we can obviously pass an image from the training dataset through the model\n",
    "# but that may not reflect too accurately how good the model actually is\n",
    "test_image, real_class = mnist_test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the image through the model\n",
    "# Note: the trained model is nowhere near perfect, meaning it will misclasify images\n",
    "# If you retrain, due to starting from different initial values for the weight and bias\n",
    "# you may end up with a model that misclasifies the image that we're testing it with now \n",
    "model_output = model(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.4316, -9.2156, -2.6557, -3.8496, -6.5907,  8.0516, -2.2205,  7.6194,\n",
       "          6.6764, 10.7622]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.argmax returns the position of the largest value in model_output\n",
    "# in our case, that is the final position (10th position, 9 because we start counting at 0)\n",
    "predicted_class = torch.argmax(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that the last value in the output tensor is bigger than the rest, so we take that value to be the class that the model predicted. The legend in the presentation tells us that it corresponds to an ankle boot. Let's plot the image and see if that's really the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26efa90c7f0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_image[0], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
